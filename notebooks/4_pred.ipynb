{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NormalDataset Normal\n",
      "\n",
      "FOLD 0\n",
      "../models/NormalDataset/NormalDataset_Fold0.pt\n",
      "cardiomegaly 0.9128443649373882\n",
      "pneumonia 0.8505479406146319\n",
      "atelectasis 0.5880058508044856\n",
      "pneumothorax 0.7191043083900226\n",
      "effusion 0.9505522733110712\n"
     ]
    }
   ],
   "source": [
    "from operator import index\n",
    "import click\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "import numpy as np\n",
    "import os.path\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torchvision.models import resnet50,densenet121\n",
    "from torchvision.transforms import v2\n",
    "from torch.nn.functional import sigmoid\n",
    "from sklearn.metrics import roc_auc_score,f1_score\n",
    "\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import GroupShuffleSplit, GroupKFold\n",
    "from src.data.pytorch_dataset import MaskingDataset\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "def valid_epoch(model,valid_dataloader):\n",
    "    model.to(DEVICE)\n",
    "    model.eval()\n",
    "    lst_labels = []\n",
    "    lst_preds = []\n",
    "    lst_probas = []\n",
    "    auc_scores = []\n",
    "    nb_pred = 0\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(valid_dataloader, 0):\n",
    "            inputs, labels = data\n",
    "            inputs,labels = inputs.float().to(DEVICE), torch.Tensor(np.array(labels)).float().to(DEVICE)\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            output_sigmoid = sigmoid(outputs)\n",
    "            lst_labels.extend(labels.cpu().detach().numpy())\n",
    "            lst_probas.extend(output_sigmoid.cpu().detach().numpy())\n",
    "            lst_preds.extend(output_sigmoid.cpu().detach().numpy()>0.5)\n",
    "        lst_labels = np.array(lst_labels)\n",
    "        lst_preds = np.array(lst_preds)\n",
    "        lst_probas = np.array(lst_probas)\n",
    "        \n",
    "        for i in range(lst_labels.shape[1]):\n",
    "            dict_val = {\"labels\":lst_labels[:,i],\"probas\":lst_probas[:,i],\"preds\":lst_preds[:,0]}\n",
    "            df = pd.DataFrame(dict_val).sort_values(by=['probas'])\n",
    "            df.to_csv(f\"./preds_{i}.csv\")\n",
    "\n",
    "            labels = lst_labels[:,i]\n",
    "            probas = lst_probas[:,i]\n",
    "            auc_score=roc_auc_score(labels,probas)\n",
    "            auc_scores.append(auc_score)\n",
    "    return auc_scores\n",
    "\n",
    "def main():\n",
    "    #Get hyperparameters \n",
    "    NB_FOLDS = int(os.environ.get(\"NB_FOLDS\"))\n",
    "    BATCH_SIZE = int(os.environ.get(\"BATCH_SIZE\"))\n",
    "    CLASSES = os.environ.get(\"CLASSES\").split(\",\")\n",
    "    models_names=[\"NormalDataset\"]\n",
    "        \n",
    "    #Load the base dataset\n",
    "    training_data = MaskingDataset(data_dir=\"../data/processed\")\n",
    "    testing_data = MaskingDataset(data_dir=\"../data/processed\")\n",
    "\n",
    "    #Split the dataset into training/testing splits\n",
    "    splitter = GroupShuffleSplit(test_size=0.2, n_splits=2, random_state = 1907)\n",
    "    train_eval_split = splitter.split(training_data.img_labels, groups=training_data.img_labels['PatientID'])\n",
    "    train_idx, test_idx = next(train_eval_split)\n",
    "    training_data.img_labels = training_data.img_labels.iloc[train_idx].reset_index(drop=True)\n",
    "    training_data.img_paths = np.array(training_data.img_paths)[train_idx]\n",
    "    training_data.roi_paths = np.array(training_data.roi_paths)[train_idx]\n",
    "\n",
    "    testing_data.img_labels = testing_data.img_labels.iloc[test_idx].reset_index(drop=True)\n",
    "    testing_data.img_paths = np.array(testing_data.img_paths)[test_idx]\n",
    "    testing_data.roi_paths = np.array(testing_data.roi_paths)[test_idx]\n",
    "    \n",
    "\n",
    "    #Create k-fold for train/val\n",
    "    group_kfold = GroupKFold(n_splits=NB_FOLDS)\n",
    "    \n",
    "    valid_params={\n",
    "        \"Normal\":{\"masking_spread\":None,\"inverse_roi\":False,\"bounding_box\":False},\n",
    "        # \"NoLung\":{\"masking_spread\":0,\"inverse_roi\":False,\"bounding_box\":False},\n",
    "        # \"NoLungBB\":{\"masking_spread\":0,\"inverse_roi\":False,\"bounding_box\":True},\n",
    "        # \"OnlyLung\":{\"masking_spread\":0,\"inverse_roi\":True,\"bounding_box\":False},\n",
    "        # \"OnlyLungBB\":{\"masking_spread\":0,\"inverse_roi\":True,\"bounding_box\":True}\n",
    "    }\n",
    "\n",
    "    with open(\"../data/interim/valid_results2.csv\", \"w\") as csv_file:\n",
    "        csv_file.write(\"training_set,valid_set,class,fold,auc\")\n",
    "\n",
    "    for model_name in models_names:\n",
    "        for param_config_name in valid_params:\n",
    "            print(model_name,param_config_name)\n",
    "            for i, (train_index,val_index) in enumerate(group_kfold.split(training_data.img_labels, groups= training_data.img_labels['PatientID'])):        \n",
    "                print(\"\\nFOLD\",i)\n",
    "                val_data = MaskingDataset(data_dir=\"../data/processed\",**valid_params[param_config_name])\n",
    "                val_data.img_labels = training_data.img_labels.iloc[val_index].reset_index(drop=True)\n",
    "                val_data.img_paths = np.array(training_data.img_paths)[val_index]\n",
    "                val_data.roi_paths = np.array(training_data.roi_paths)[val_index]\n",
    "\n",
    "                valid_dataloader = DataLoader(val_data, batch_size=BATCH_SIZE)\n",
    "                \n",
    "                \n",
    "                #Define model, loss and optimizer\n",
    "                model = densenet121(weights='DEFAULT')#Weights pretrained on imagenet_1k\n",
    "                \n",
    "                # Freeze every layer except last denseblock and classifier\n",
    "                for param in model.parameters():\n",
    "                    param.requires_grad = False\n",
    "                for param in model.features.denseblock4.denselayer16.parameters():\n",
    "                    param.requires_grad = True\n",
    "               \n",
    "                kernel_count = model.classifier.in_features\n",
    "                model.classifier = torch.nn.Sequential(\n",
    "                 torch.nn.Flatten(),\n",
    "                 torch.nn.Linear(kernel_count, len(CLASSES))\n",
    "                )\n",
    "                \n",
    "                try:\n",
    "                    print(f\"../models/{model_name}/{model_name}_Fold{i}.pt\")\n",
    "                    model.load_state_dict(torch.load(f\"../models/{model_name}/{model_name}_Fold{i}.pt\"))\n",
    "                    model.to(DEVICE)\n",
    "                except FileNotFoundError as e:\n",
    "                    print(\"No model saved for fold\",i)\n",
    "                    continue\n",
    "\n",
    "                val_metric = valid_epoch(model,valid_dataloader)\n",
    "                with open(\"../data/interim/valid_results2.csv\", \"a\") as csv_file:\n",
    "                    for j,c in enumerate(CLASSES):\n",
    "                        csv_file.write(f\"\\n{model_name},{param_config_name},{c},{i},{val_metric[j]}\")\n",
    "                        print(c,val_metric[j])\n",
    "                break\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    load_dotenv(find_dotenv())\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mmc_masking",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
